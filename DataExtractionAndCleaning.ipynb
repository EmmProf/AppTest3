{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DataExtractionAndCleaning.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNMM89ffi7QdjuPpGy/Amx/"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ni6rDEjN0Vl9"},"source":["Using the package [Faker](https://faker.readthedocs.io/en/master/) to produce a dataframe <code> namesWithInfo</code> containing names with gender, firstVsLast and locality information"]},{"cell_type":"code","metadata":{"id":"3d22I0JZrtWq"},"source":["!pip install Faker"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1KEw_T15cdr7"},"source":["import pandas as pd\n","from faker import Faker #we use the package faker to generate names with gender, firstVsLast and locality information\n","Faker.seed(123) #set the seed for reproducibility"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"juSdEwsRsIra"},"source":["#correspondance between language codes and names. (Taken from googletrans package, added dk for danish, tw for twi (ghana dialect))\n","LANGUAGES = {'af': 'afrikaans','am': 'amharic','ar': 'arabic','az': 'azerbaijani','be': 'belarusian','bg': 'bulgarian','bn': 'bengali',\n","             'bs': 'bosnian','ca': 'catalan','ceb': 'cebuano','co': 'corsican','cs': 'czech','cy': 'welsh','dk':'danish','da': 'danish','de': 'german',\n","             'el': 'greek','en': 'english','eo': 'esperanto','es': 'spanish','et': 'estonian','eu': 'basque','fa': 'persian','fi': 'finnish',\n","             'fr': 'french','fy': 'frisian','ga': 'irish','gd': 'scots gaelic','gl': 'galician','gu': 'gujarati','ha': 'hausa','haw': 'hawaiian',\n","             'he': 'hebrew','hi': 'hindi','hmn': 'hmong','hr': 'croatian','ht': 'haitian creole','hu': 'hungarian','hy': 'armenian','id': 'indonesian',\n","             'ig': 'igbo','is': 'icelandic','it': 'italian','iw': 'hebrew','ja': 'japanese','jw': 'javanese','ka': 'georgian','kk': 'kazakh',\n","             'km': 'khmer','kn': 'kannada','ko': 'korean','ku': 'kurdish (kurmanji)','ky': 'kyrgyz','la': 'latin','lb': 'luxembourgish',\n","             'lo': 'lao','lt': 'lithuanian','lv': 'latvian','mg': 'malagasy','mi': 'maori','mk': 'macedonian','ml': 'malayalam','mn': 'mongolian',\n","             'mr': 'marathi','ms': 'malay','mt': 'maltese','my': 'myanmar (burmese)','ne': 'nepali','nl': 'dutch','no': 'norwegian','ny': 'chichewa',\n","             'or': 'odia','pa': 'punjabi','pl': 'polish','ps': 'pashto','pt': 'portuguese','ro': 'romanian','ru': 'russian','sd': 'sindhi',\n","             'si': 'sinhala','sk': 'slovak','sl': 'slovenian','sm': 'samoan','sn': 'shona','so': 'somali','sq': 'albanian','sr': 'serbian',\n","             'st': 'sesotho','su': 'sundanese','sv': 'swedish','sw': 'swahili','ta': 'tamil','te': 'telugu','tg': 'tajik','th': 'thai','tw':'twi (ghana dialect)',\n","             'tl': 'filipino','tr': 'turkish','ug': 'uyghur','uk': 'ukrainian','ur': 'urdu','uz': 'uzbek','vi': 'vietnamese','xh': 'xhosa',\n","             'yi': 'yiddish','yo': 'yoruba','zh-cn': 'chinese (simplified)','zh-tw': 'chinese (traditional)','zu': 'zulu'}\n","             \n","#after some side preprocessing on excel (removing inactive locals...), hardcode a list of valid Faker local codes to produce names from different localities. (tw_GH stands for Twi, Ghanaian)\n","FAKERLOCALS = {'ar_AA': 'Arabic (Egypt)','ar_PS': 'Arabic (Palestine)','ar_SA': 'Arabic (Saudi Arabia)','bg_BG': 'Bulgarian','cs_CZ': 'Czech','de_AT': 'German (Austria)',\n","               'de_CH': 'German (Switzerland)','de_DE': 'German','dk_DK': 'Danish','el_GR': 'Greek','en_AU': 'English (Australia)','en_CA': 'English (Canada)',\n","               'en_GB': 'English (Great Britain)','en_IN': 'English (India)','en_NZ': 'English (New Zealand)','en_US': 'English (United State)','es_ES': 'Spanish (Spain)',\n","               'es_MX': 'Spanish (Mexico)','et_EE': 'Estonian','fa_IR': 'Persian (Iran)','fi_FI': 'Finnish','fr_CH': 'French (Switzerland)','fr_FR': 'French',\n","               'fr_QC': 'French (Quebec)','he_IL': 'Hebrew (Israel)','hi_IN': 'Hindi','hr_HR': 'Croatian','hu_HU': 'Hungarian','hy_AM': 'Armenian',\n","               'id_ID': 'Indonesia','it_IT': 'Italian','ja_JP': 'Japanese','ka_GE': 'Georgian (Georgia)','ko_KR': 'Korean','lt_LT': 'Lithuanian','lv_LV': 'Latvian',\n","               'ne_NP': 'Nepali','nl_NL': 'Dutch (Netherlands)','no_NO': 'Norwegian','pl_PL': 'Polish','pt_BR': 'Portuguese (Brazil)','pt_PT': 'Portuguese (Portugal)',\n","               'ro_RO': 'Romanian','ru_RU': 'Russian','sl_SI': 'Slovene','sv_SE': 'Swedish','ta_IN': 'Tamil (India)','th_TH': 'Thai (Thailand)','tr_TR': 'Turkish',\n","               'tw_GH': 'Twi (Ghana)','uk_UA': 'Ukrainian','zh_CN': 'Chinese (China)','zh_TW': 'Chinese (Taiwan)'}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9vdlYtXicdsB"},"source":["#we use Faker to generate fake names, and stop when all possible names have been generated.\n","#Unfortunately it was not possible to get a full list of names for every locals programatically\n","#construct a dictionnary of names using different Faker generators for locality, gender, and firstVsLast\n","\n","#note that this step is packaged in the function produceNamesWithInfoDataset in utils.py\n","\n","ITER_MAX = 2000000\n","PATIENCE = 4\n","\n","namesDict = dict()\n","\n","#loop over the different localities in Faker\n","for code in FAKERLOCALS.keys():\n","    namesLocal = dict()\n","    fake = Faker(code)\n","    #construct a dict of generators for different kind of names (first, last, male, female name)\n","    nameGenerators = dict(FNFemale = fake.first_name_female, FNMale = fake.first_name_male,LN = fake.last_name)\n","\n","    #loop over the different types of names\n","    for kind, generator in nameGenerators.items():\n","        #print(kind,\" ,\", code) #debug\n","        namesLocalGenderFstvsLst = []\n","        nuniquePrev = 0\n","        countSame = 0\n","        iterNb = 0\n","\n","        #could not get a full list of the names Faker uses for every locality\n","        #So we generate names until we do not get any novelty\n","        while countSame < PATIENCE and iterNb < ITER_MAX:\n","            iterNb += 1\n","            #Faker will generate more names by making composite names (e.g. Smith-Doe) [could have used set() here]\n","            namesLocalGenderFstvsLst += generator().split(\"-\")\n","            # check every 5000 iterations how much new names we are getting\n","            if iterNb % 5000 == 0: \n","                nunique = len(set(namesLocalGenderFstvsLst))\n","                if nuniquePrev == nunique : \n","                    countSame += 1 \n","                nuniquePrev = nunique\n","\n","        namesLocal[kind] = list(set(namesLocalGenderFstvsLst))\n","\n","    namesDict[code] = namesLocal"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CSXw4fdgcdsD"},"source":["#build correspondance between namesDict keys and names features\n","correspGender = dict(FNFemale = \"Female\", FNMale = \"Male\",LN = \"Last\")\n","correspFirstVsLast = dict(FNFemale = \"Firstname\", FNMale = \"Firstname\",LN = \"Lastname\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vGUnE-jUcdsF"},"source":["#extract columns to input in a dataframe\n","namesList = []\n","firstVsLast = []\n","gender = []\n","locality1List = []\n","locality2List= []\n","\n","for locality2,namesLocalDict in namesDict.items():\n","    for genderFstvsLst,names in namesLocalDict.items():\n","        #print(locality,\" \", genderFstvsLst,\" \",len(names)) #debug\n","        namesList += names\n","    \n","        firstVsLast += [correspFirstVsLast[genderFstvsLst]]*len(names)\n","        gender += [correspGender[genderFstvsLst]]*len(names)\n","\n","\n","        if locality2 == \"zh_TW\": locality1 = \"zh-tw\"\n","        elif locality2 == \"zh_CN\": locality1 = \"zh-cn\"\n","        else: locality1 = locality2.split(\"_\")[0]\n","\n","        locality1List += [locality1]*len(names)\n","        locality2List += [locality2]*len(names)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aJ-zrY7tcdsI"},"source":["#we do not want to recognize names because they are capitalized\n","namesList = [name.lower() for name in namesList]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FPJtUcn9cdsL"},"source":["#construct a dataframe with columns given by the previously constructed lists\n","namesWithInfo = pd.DataFrame(dict(names=namesList,firstVsLast = firstVsLast,gender = gender,locality1=locality1List,locality2=locality2List))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FTeCIwvMmPEg"},"source":["#set column with names instead of codes\n","namesWithInfo[\"locality1Names\"] = [LANGUAGES[key] for key in namesWithInfo.locality1]\n","namesWithInfo[\"locality2Names\"] = [FAKERLOCALS[key] for key in namesWithInfo.locality2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xtOoWecVoaaW"},"source":["#reorder columns\n","namesWithInfo = namesWithInfo[[\"names\",\"firstVsLast\",\"gender\",\"locality1\",\"locality1Names\",\"locality2\",\"locality2Names\"]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JIcz3SFecdsR"},"source":["#remove some names containing weird characters, for example composed names with \"/\"\n","excludeChars = [\"(\",\")\",\".\",\":\",\";\",\"&\",\"/\",\"0\",\"8\",\"[\"]\n","namesWithInfo = namesWithInfo.loc[[all(exChar not in l for exChar in excludeChars) for l in namesWithInfo.names],:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dDW842MunKQ7"},"source":["#remove empty names\n","namesWithInfo = namesWithInfo.loc[[len(l) != 0 for l in namesWithInfo.names],:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tEhsjjpzjz9v"},"source":["#reset index because removing rows messed up the index\n","namesWithInfo.reset_index(drop=True,inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B4Jn73d6j_7H"},"source":["#namesWithInfo.to_csv(path_or_buf=\"namesWithInfo.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LuCLKOHn6qmh","executionInfo":{"status":"ok","timestamp":1599466213099,"user_tz":-120,"elapsed":549,"user":{"displayName":"Emmanuel Profumo","photoUrl":"","userId":"02754790487851517033"}},"outputId":"3cda79a0-09cb-4a82-90b2-aec879327aaa","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Some names are repeated between the different categories\n","len(namesWithInfo),len(namesWithInfo.names.unique())"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(53869, 34580)"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"oWsaV8KNYaNe","executionInfo":{"status":"ok","timestamp":1603879158073,"user_tz":-60,"elapsed":518,"user":{"displayName":"Emmanuel Profumo","photoUrl":"","userId":"02754790487851517033"}},"outputId":"b6414bf0-8788-4222-cf26-ce24a4a86942","colab":{"base_uri":"https://localhost:8080/","height":197}},"source":["namesWithInfo.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>names</th>\n","      <th>firstVsLast</th>\n","      <th>gender</th>\n","      <th>locality1</th>\n","      <th>locality1Names</th>\n","      <th>locality2</th>\n","      <th>locality2Names</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ابتهاج</td>\n","      <td>Firstname</td>\n","      <td>Female</td>\n","      <td>ar</td>\n","      <td>arabic</td>\n","      <td>ar_AA</td>\n","      <td>Arabic (Egypt)</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ريناد</td>\n","      <td>Firstname</td>\n","      <td>Female</td>\n","      <td>ar</td>\n","      <td>arabic</td>\n","      <td>ar_AA</td>\n","      <td>Arabic (Egypt)</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>يسرى</td>\n","      <td>Firstname</td>\n","      <td>Female</td>\n","      <td>ar</td>\n","      <td>arabic</td>\n","      <td>ar_AA</td>\n","      <td>Arabic (Egypt)</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>دارين</td>\n","      <td>Firstname</td>\n","      <td>Female</td>\n","      <td>ar</td>\n","      <td>arabic</td>\n","      <td>ar_AA</td>\n","      <td>Arabic (Egypt)</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>لتين</td>\n","      <td>Firstname</td>\n","      <td>Female</td>\n","      <td>ar</td>\n","      <td>arabic</td>\n","      <td>ar_AA</td>\n","      <td>Arabic (Egypt)</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    names firstVsLast  gender  ... locality1Names locality2  locality2Names\n","0  ابتهاج   Firstname  Female  ...         arabic     ar_AA  Arabic (Egypt)\n","1   ريناد   Firstname  Female  ...         arabic     ar_AA  Arabic (Egypt)\n","2    يسرى   Firstname  Female  ...         arabic     ar_AA  Arabic (Egypt)\n","3   دارين   Firstname  Female  ...         arabic     ar_AA  Arabic (Egypt)\n","4    لتين   Firstname  Female  ...         arabic     ar_AA  Arabic (Egypt)\n","\n","[5 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":117}]},{"cell_type":"markdown","metadata":{"id":"VCS9B4cqUgVN"},"source":["Produce a list of names and a list of multiple features for the different names, to fit to a multi-label classification task."]},{"cell_type":"code","metadata":{"id":"zYntld-MtWGc"},"source":["import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vIqRiMysz-gs"},"source":["#after some experiments we exclude names whose locality is perfectly inferred from their alphabet. This reduces the vocabulary.\n","easyLanguages = [\"arabic\",\"armenian\",\"nepali\",\"hebrew\",\"bulgarian\",\n","                 \"georgian\",\"hindi\",\"thai\",\"tamil\",\"greek\",\"korean\",\n","                 \"chinese (simplified)\",\"chinese (traditional)\",\n","                 \"japanese\",\"persian\",\"ukrainian\"]\n","                 \n","namesData = pd.read_csv(filepath_or_buffer=\"namesWithInfo.csv\",index_col=0)\n","namesData = namesData.loc[~namesData.locality1Names.isin(easyLanguages)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wWhrMkPb-lJI"},"source":["#group by names, mapping a name to all its possible features (locality,gender,firstVsLast)\n","namesVsFeatures = namesData.groupby(\"names\").apply(lambda g: list(set(g.locality1Names)) + list(set(g.gender)) + list(set(g.firstVsLast)))\n","features = namesVsFeatures.values\n","names = namesVsFeatures.index.values\n","names = [name.strip().lower() for name in names]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xxij0PV_he6W"},"source":["#save the names and features data\n","with open(\"ressources/names.txt\",\"w\") as f:\n","    for name in names:\n","      f.write(name +'\\n')\n","      \n","np.save(\"ressources/features.npy\",features)"],"execution_count":null,"outputs":[]}]}